# 04 â€¢ Observabilidade de LLMs (LLMOps / SRE for AI)

IA em produÃ§Ã£o **nÃ£o pode ser caixa-preta**.  
Sem observabilidade, nÃ£o existe confiabilidade, previsibilidade de custo ou seguranÃ§a.

Este mÃ³dulo aplica **princÃ­pios de SRE** diretamente a sistemas GenAI.

---

## ğŸ¯ Objetivo
Operar LLMs como **sistemas crÃ­ticos**, com mÃ©tricas, SLIs, SLOs e resposta a incidentes.

---

## ğŸ”­ O que observar em sistemas GenAI

### 1ï¸âƒ£ LatÃªncia
- Tempo total de resposta
- LatÃªncia por etapa (retrieve â†’ prompt â†’ inferÃªncia)
- p95 / p99

### 2ï¸âƒ£ Qualidade
- Groundedness (uso correto do contexto)
- Factualidade
- Taxa de retrabalho humano

### 3ï¸âƒ£ Custo
- Tokens por request
- Custo por usuÃ¡rio
- Custo por tarefa (agent)

### 4ï¸âƒ£ Confiabilidade
- Erros por tipo
- Fallbacks acionados
- Respostas vazias ou truncadas

---

## ğŸ“Š SLIs e SLOs para IA

| MÃ©trica | Exemplo de SLO |
|------|----------------|
| LatÃªncia p95 | < 2s |
| Respostas vÃ¡lidas | > 99% |
| Groundedness | > 95% |
| Custo por request | < $0.02 |

---

## ğŸ§  Logs que realmente importam

Cada requisiÃ§Ã£o deve registrar:
- Prompt version
- Context size
- Tokens (input/output)
- Modelo utilizado
- DecisÃ£o do agente (se aplicÃ¡vel)
- Resultado final

---

## âš ï¸ Anti-padrÃµes comuns
- Apenas logs de erro
- MÃ©tricas sÃ³ de infraestrutura
- NÃ£o correlacionar custo com resposta
- NÃ£o versionar prompts

---

## ğŸ’¼ O que este mÃ³dulo valida no mercado
- Mentalidade **SRE aplicada Ã  IA**
- Capacidade de operar LLMs em produÃ§Ã£o
- Responsabilidade sobre custo e qualidade

---
